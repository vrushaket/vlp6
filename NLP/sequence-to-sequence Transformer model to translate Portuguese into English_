{"cells":[{"cell_type":"markdown","metadata":{"id":"Fo1P7AN4lzdi"},"source":["<img src=\"https://www.tensorflow.org/images/tutorials/transformer/apply_the_transformer_to_machine_translation.gif\" alt=\"Applying the Transformer to machine translation\">\n","\n","Figure 1: Applying the Transformer to machine translation. Source: [Google AI Blog](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html).\n"]},{"cell_type":"markdown","metadata":{"id":"RAxfGTJJYbQi"},"source":["That's a lot to digest, the goal of this tutorial is to break it down into easy to understand parts. In this tutorial you will:\n","\n","- Prepare the data.\n","- Implement necessary components:\n","  - Positional embeddings.\n","  - Attention layers.\n","  - The encoder and decoder.\n","- Build & train the Transformer.\n","- Generate translations.\n","- Export the model."]},{"cell_type":"markdown","metadata":{"id":"swymtxpl7W7w"},"source":["## Setup"]},{"cell_type":"markdown","metadata":{"id":"OfV1batAwq9j"},"source":["Begin by installing [TensorFlow Datasets](https://tensorflow.org/datasets) for loading the dataset and [TensorFlow Text](https://www.tensorflow.org/text) for text preprocessing:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XFG0NDRu5mYQ"},"outputs":[],"source":["# Install the most re version of TensorFlow to use the improved\n","# masking support for `tf.keras.layers.MultiHeadAttention`.\n","!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n","!pip uninstall -y -q tensorflow keras tensorflow-estimator tensorflow-text\n","!pip install protobuf~=3.20.3\n","!pip install -q tensorflow_datasets\n","!pip install -q -U tensorflow-text tensorflow"]},{"cell_type":"markdown","metadata":{"id":"0GYpLBSjxJmG"},"source":["Import the necessary modules:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JjJJyJTZYebt"},"outputs":[],"source":["import logging\n","import time\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import tensorflow_datasets as tfds\n","import tensorflow as tf\n","\n","import tensorflow_text"]},{"cell_type":"markdown","metadata":{"id":"Xf_WUi2HLhzf"},"source":["## Data handling\n","\n","This section downloads the dataset and the subword tokenizer, from [this tutorial](https://www.tensorflow.org/text/guide/subwords_tokenizer), then wraps it all up in a `tf.data.Dataset` for training.\n","\n"," <section class=\"expandable tfo-display-only-on-site\">\n"," <button type=\"button\" class=\"button-red button expand-control\">Toggle section</button>\n"]},{"cell_type":"markdown","metadata":{"id":"-cCvXbPkccV1"},"source":["### Download the dataset"]},{"cell_type":"markdown","metadata":{"id":"LTEVgBxklzdq"},"source":["Use TensorFlow Datasets to load the [Portuguese-English translation dataset](https://www.tensorflow.org/datasets/catalog/ted_hrlr_translate#ted_hrlr_translatept_to_en)D Talks Open Translation Project. This dataset contains approximately 52,000 training, 1,200 validation and 1,800 test examples."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8q9t4FmN96eN"},"outputs":[],"source":["examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en',\n","                               with_info=True,\n","                               as_supervised=True)\n","\n","train_examples, val_examples = examples['train'], examples['validation']"]},{"cell_type":"markdown","metadata":{"id":"ZA4cw7F_DmSt"},"source":["The `tf.data.Dataset` object returned by TensorFlow Datasets yields pairs of text examples:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CZFAMZJyDrFn"},"outputs":[],"source":["for pt_examples, en_examples in train_examples.batch(3).take(1):\n","  print('> Examples in Portuguese:')\n","  for pt in pt_examples.numpy():\n","    print(pt.decode('utf-8'))\n","  print()\n","\n","  print('> Examples in English:')\n","  for en in en_examples.numpy():\n","    print(en.decode('utf-8'))"]},{"cell_type":"markdown","metadata":{"id":"eJxTd6aVnZyh"},"source":["### Set up the tokenizer"]},{"cell_type":"markdown","metadata":{"id":"Mopr6oKUlzds"},"source":["Now that you have loaded the dataset, you need to tokenize the text, so that each element is represented as a [token](https://developers.google.com/machine-learning/glossary#token) or token ID (a numeric representation).\n","\n","Tokenization is the process of breaking up text, into \"tokens\". Depending on the tokenizer, these tokens can represent sentence-pieces, words, subwords, or characters. To learn more about tokenization, visit [this guide](https://www.tensorflow.org/text/guide/tokenizers)."]},{"cell_type":"markdown","metadata":{"id":"GJr_8Jz9FKgu"},"source":["This tutorial uses the tokenizers built in the [subword tokenizer](https://www.tensorflow.org/text/guide/subwords_tokenizer) tutorial. That tutorial optimizes two `text.BertTokenizer` objects (one for English, one for Portuguese) for **this dataset** and exports them in a TensorFlow `saved_model` format.\n","\n","> Note: This is different from the [original paper](https://arxiv.org/pdf/1706.03762.pdf), section 5.1, where they used a single byte-pair tokenizer for both the source and target with a vocabulary-size of 37000.\n","\n","Download, extract, and import the `saved_model`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QToMl0NanZPr"},"outputs":[],"source":["model_name = 'ted_hrlr_translate_pt_en_converter'\n","tf.keras.utils.get_file(\n","    f'{model_name}.zip',\n","    f'https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip',\n","    cache_dir='.', cache_subdir='', extract=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h5dbGnPXnuI1"},"outputs":[],"source":["tokenizers = tf.saved_model.load(model_name)"]},{"cell_type":"markdown","metadata":{"id":"CexgkIS1lzdt"},"source":["The `tf.saved_model` contains two text tokenizers, one for English and one for Portuguese. Both have the same methods:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s-PCJijfcZ9_"},"outputs":[],"source":["[item for item in dir(tokenizers.en) if not item.startswith('_')]"]},{"cell_type":"markdown","metadata":{"id":"fUBljDDEFWUC"},"source":["The `tokenize` method converts a batch of strings to a padded-batch of token IDs. This method splits punctuation, lowercases and unicode-normalizes the input before tokenizing. That standardization is not visible here because the input data is already standardized."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z_gPC5iwFXfU"},"outputs":[],"source":["print('> This is a batch of strings:')\n","for en in en_examples.numpy():\n","  print(en.decode('utf-8'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uSkM7z8JFaVO"},"outputs":[],"source":["encoded = tokenizers.en.tokenize(en_examples)\n","\n","print('> This is a padded-batch of token IDs:')\n","for row in encoded.to_list():\n","  print(row)"]},{"cell_type":"markdown","metadata":{"id":"nBkv7XeBFa8_"},"source":["The `detokenize` method attempts to convert these token IDs back to human-readable text: "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-CFS5aAxFdpP"},"outputs":[],"source":["round_trip = tokenizers.en.detokenize(encoded)\n","\n","print('> This is human-readable text:')\n","for line in round_trip.numpy():\n","  print(line.decode('utf-8'))"]},{"cell_type":"markdown","metadata":{"id":"G-2gMSBBU-AE"},"source":["The lower level `lookup` method converts from token-IDs to token text:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XaCeOnswVAhI"},"outputs":[],"source":["print('> This is the text split into tokens:')\n","tokens = tokenizers.en.lookup(encoded)\n","tokens"]},{"cell_type":"markdown","metadata":{"id":"pR3vZJf1Yhg_"},"source":["The output demonstrates the \"subword\" aspect of the subword tokenization.\n","\n","For example, the word `'searchability'` is decomposed into `'search'` and `'##ability'`, and the word `'serendipity'` into `'s'`, `'##ere'`, `'##nd'`, `'##ip'` and `'##ity'`.\n","\n","Note that the tokenized text includes `'[START]'` and `'[END]'` tokens."]},{"cell_type":"markdown","metadata":{"id":"g_4vdnhSaATh"},"source":["The distribution of tokens per example in the dataset is as follows:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KRbke-iaaHFI"},"outputs":[],"source":["lengths = []\n","\n","for pt_examples, en_examples in train_examples.batch(1024):\n","  pt_tokens = tokenizers.pt.tokenize(pt_examples)\n","  lengths.append(pt_tokens.row_lengths())\n","  \n","  en_tokens = tokenizers.en.tokenize(en_examples)\n","  lengths.append(en_tokens.row_lengths())\n","  print('.', end='', flush=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ucA1q3GaK_n"},"outputs":[],"source":["all_lengths = np.concatenate(lengths)\n","\n","plt.hist(all_lengths, np.linspace(0, 500, 101))\n","plt.ylim(plt.ylim())\n","max_length = max(all_lengths)\n","plt.plot([max_length, max_length], plt.ylim())\n","plt.title(f'Maximum tokens per example: {max_length}');"]},{"cell_type":"markdown","metadata":{"id":"-Yb35sTJcZq9"},"source":["### Set up a data pipeline with `tf.data`"]},{"cell_type":"markdown","metadata":{"id":"JZHsns5obJhN"},"source":["The following function takes batches of text as input, and converts them to a format suitable for training. \n","\n","1. It tokenizes them into ragged batches.\n","2. It trims each to be no longer than `MAX_TOKENS`.\n","3. It splits the target (English) tokens into inputs and labels. These are shifted by one step so that at each input location the `label` is the id of the next token.\n","4. It converts the `RaggedTensor`s to padded dense `Tensor`s.\n","5. It returns an `(inputs, labels)` pair.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6shgzEck3FiV"},"outputs":[],"source":["MAX_TOKENS=128\n","def prepare_batch(pt, en):\n","    pt = tokenizers.pt.tokenize(pt)      # Output is ragged.\n","    pt = pt[:, :MAX_TOKENS]    # Trim to MAX_TOKENS.\n","    pt = pt.to_tensor()  # Convert to 0-padded dense Tensor\n","\n","    en = tokenizers.en.tokenize(en)\n","    en = en[:, :(MAX_TOKENS+1)]\n","    en_inputs = en[:, :-1].to_tensor()  # Drop the [END] tokens\n","    en_labels = en[:, 1:].to_tensor()   # Drop the [START] tokens\n","\n","    return (pt, en_inputs), en_labels"]},{"cell_type":"markdown","metadata":{"id":"dAroQ6xelzdx"},"source":["The function below converts a dataset of text examples into data of batches for training. \n","\n","1. It tokenizes the text, and filters out the sequences that are too long.\n","   (The `batch`/`unbatch` is included because the tokenizer is much more efficient on large batches).\n","2. The `cache` method ensures that that work is only executed once.\n","3. Then `shuffle` and, `dense_to_ragged_batch` randomize the order and assemble batches of examples. \n","4. Finally `prefetch` runs the dataset in parallel with the model to ensure that data is available when needed. See [Better performance with the `tf.data`](https://www.tensorflow.org/guide/data_performance.ipynb) for details."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bcRp7VcQ5m6g"},"outputs":[],"source":["BUFFER_SIZE = 20000\n","BATCH_SIZE = 64"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BUN_jLBTwNxk"},"outputs":[],"source":["def make_batches(ds):\n","  return (\n","      ds\n","      .shuffle(BUFFER_SIZE)\n","      .batch(BATCH_SIZE)\n","      .map(prepare_batch, tf.data.AUTOTUNE)\n","      .prefetch(buffer_size=tf.data.AUTOTUNE))"]},{"cell_type":"markdown","metadata":{"id":"FX_h3tCnwgR4"},"source":[" </section>"]},{"cell_type":"markdown","metadata":{"id":"itSWqk-ivrRg"},"source":["## Test the Dataset "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BSswr5TKvoNM"},"outputs":[],"source":["# Create training and validation set batches.\n","train_batches = make_batches(train_examples)\n","val_batches = make_batches(val_examples)"]},{"cell_type":"markdown","metadata":{"id":"PSufllC7wooA"},"source":["The resulting `tf.data.Dataset` objects are setup for training with Keras.\n","Keras `Model.fit` training expects `(inputs, labels)` pairs.\n","The `inputs` are pairs of tokenized Portuguese and English sequences, `(pt, en)`.\n","The `labels` are the same English sequences shifted by 1.\n","This shift is so that at each location input `en` sequence, the `label` in the next token.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CAw2XjRwLFWr"},"outputs":[],"source":["for (pt, en), en_labels in train_batches.take(1):\n","  break\n","\n","print(pt.shape)\n","print(en.shape)\n","print(en_labels.shape)"]},{"cell_type":"markdown","metadata":{"id":"Tzo3JKaqx46g"},"source":["The `en` and `en_labels` are the same, just shifted by 1:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"apFeC-WWxzR4"},"outputs":[],"source":["print(en[0][:10])\n","print(en_labels[0][:10])"]},{"cell_type":"markdown","metadata":{"id":"7e7hKcxn6-zd"},"source":["## Define the components"]},{"cell_type":"markdown","metadata":{"id":"HVE5j6JlcAps"},"source":["There's a lot going on inside a Transformer. The important things to remember are:\n","\n","1. It follows the same general pattern as a standard sequence-to-sequence model with an encoder and a decoder.\n","2. If you work through it step by step it will all make sense."]},{"cell_type":"markdown","metadata":{"id":"YS75Y-9-lkzn"},"source":["### The embedding and positional encoding layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Rz82wEs5biZ"},"outputs":[],"source":["def positional_encoding(length, depth):\n","  depth = depth/2\n","\n","  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n","  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n","  \n","  angle_rates = 1 / (10000**depths)         # (1, depth)\n","  angle_rads = positions * angle_rates      # (pos, depth)\n","\n","  pos_encoding = np.concatenate(\n","      [np.sin(angle_rads), np.cos(angle_rads)],\n","      axis=-1) \n","\n","  return tf.cast(pos_encoding, dtype=tf.float32)"]},{"cell_type":"markdown","metadata":{"id":"Ra1IcbzFhnmF"},"source":["The position encoding function is a stack of sines and cosines that vibrate at different frequencies depending on their location along the depth of the embedding vector. They vibrate across the position axis."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AKf4Ky2dhg0L"},"outputs":[],"source":["#@title\n","pos_encoding = positional_encoding(length=2048, depth=512)\n","\n","# Check the shape.\n","print(pos_encoding.shape)\n","\n","# Plot the dimensions.\n","plt.pcolormesh(pos_encoding.numpy().T, cmap='RdBu')\n","plt.ylabel('Depth')\n","plt.xlabel('Position')\n","plt.colorbar()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"eKqVkl9Jlzg6"},"source":["By definition these vectors align well with nearby vectors along the position axis. Below the position encoding vectors are normalized and the vector from position `1000` is compared, by dot-product, to all the others:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CXY-8_uEhcRD"},"outputs":[],"source":["#@title\n","pos_encoding/=tf.norm(pos_encoding, axis=1, keepdims=True)\n","p = pos_encoding[1000]\n","dots = tf.einsum('pd,d -> p', pos_encoding, p)\n","plt.subplot(2,1,1)\n","plt.plot(dots)\n","plt.ylim([0,1])\n","plt.plot([950, 950, float('nan'), 1050, 1050],\n","         [0,1,float('nan'),0,1], color='k', label='Zoom')\n","plt.legend()\n","plt.subplot(2,1,2)\n","plt.plot(dots)\n","plt.xlim([950, 1050])\n","plt.ylim([0,1])\n"]},{"cell_type":"markdown","metadata":{"id":"LUknPLlVm99o"},"source":["So use this to create a `PositionEmbedding` layer that looks-up a token's embedding vector and adds the position vector:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"838tmM1cm9cB"},"outputs":[],"source":["class PositionalEmbedding(tf.keras.layers.Layer):\n","  def __init__(self, vocab_size, d_model):\n","    super().__init__()\n","    self.d_model = d_model\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True) \n","    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n","\n","  def compute_mask(self, *args, **kwargs):\n","    return self.embedding.compute_mask(*args, **kwargs)\n","\n","  def call(self, x):\n","    length = tf.shape(x)[1]\n","    x = self.embedding(x)\n","    # This factor sets the relative scale of the embedding and positonal_encoding.\n","    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","    x = x + self.pos_encoding[tf.newaxis, :length, :]\n","    return x\n"]},{"cell_type":"markdown","metadata":{"id":"QpWnjwygmw-x"},"source":["> Note: The [original paper](https://arxiv.org/pdf/1706.03762.pdf), section 3.4 and 5.1, uses a single tokenizer and weight matrix for both the source and target languages. This tutorial uses two separate tokenizers and weight matrices."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tfz-EaCEDfUJ"},"outputs":[],"source":["embed_pt = PositionalEmbedding(vocab_size=tokenizers.pt.get_vocab_size(), d_model=512)\n","embed_en = PositionalEmbedding(vocab_size=tokenizers.en.get_vocab_size(), d_model=512)\n","\n","pt_emb = embed_pt(pt)\n","en_emb = embed_en(en)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3fJZ_ArLELhJ"},"outputs":[],"source":["en_emb._keras_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5VLa5QcdPpv5"},"outputs":[],"source":["class BaseAttention(tf.keras.layers.Layer):\n","  def __init__(self, **kwargs):\n","    super().__init__()\n","    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n","    self.layernorm = tf.keras.layers.LayerNormalization()\n","    self.add = tf.keras.layers.Add()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kfHVbJUWv8qp"},"outputs":[],"source":["class CrossAttention(BaseAttention):\n","  def call(self, x, context):\n","    attn_output, attn_scores = self.mha(\n","        query=x,\n","        key=context,\n","        value=context,\n","        return_attention_scores=True)\n","   \n","    # Cache the attention scores for plotting later.\n","    self.last_attn_scores = attn_scores\n","\n","    x = self.add([x, attn_output])\n","    x = self.layernorm(x)\n","\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qw1FJV5qRk79"},"outputs":[],"source":["sample_ca = CrossAttention(num_heads=2, key_dim=512)\n","\n","print(pt_emb.shape)\n","print(en_emb.shape)\n","print(sample_ca(en_emb, pt_emb).shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RNqoTpn1wB3i"},"outputs":[],"source":["class GlobalSelfAttention(BaseAttention):\n","  def call(self, x):\n","    attn_output = self.mha(\n","        query=x,\n","        value=x,\n","        key=x)\n","    x = self.add([x, attn_output])\n","    x = self.layernorm(x)\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jPn2D07-Jcmj"},"outputs":[],"source":["sample_gsa = GlobalSelfAttention(num_heads=2, key_dim=512)\n","\n","print(pt_emb.shape)\n","print(sample_gsa(pt_emb).shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4MMQ-AfKD99_"},"outputs":[],"source":["class CausalSelfAttention(BaseAttention):\n","  def call(self, x):\n","    attn_output = self.mha(\n","        query=x,\n","        value=x,\n","        key=x,\n","        use_causal_mask = True)\n","    x = self.add([x, attn_output])\n","    x = self.layernorm(x)\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x4dQuzvlD99_"},"outputs":[],"source":["sample_csa = CausalSelfAttention(num_heads=2, key_dim=512)\n","\n","print(en_emb.shape)\n","print(sample_csa(en_emb).shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bwKlheQ-WVxl"},"outputs":[],"source":["out1 = sample_csa(embed_en(en[:, :3])) \n","out2 = sample_csa(embed_en(en))[:, :3]\n","\n","tf.reduce_max(abs(out1 - out2)).numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rAYLeu0uwXYK"},"outputs":[],"source":["class FeedForward(tf.keras.layers.Layer):\n","  def __init__(self, d_model, dff, dropout_rate=0.1):\n","    super().__init__()\n","    self.seq = tf.keras.Sequential([\n","      tf.keras.layers.Dense(dff, activation='relu'),\n","      tf.keras.layers.Dense(d_model),\n","      tf.keras.layers.Dropout(dropout_rate)\n","    ])\n","    self.add = tf.keras.layers.Add()\n","    self.layer_norm = tf.keras.layers.LayerNormalization()\n","\n","  def call(self, x):\n","    x = self.add([x, self.seq(x)])\n","    x = self.layer_norm(x) \n","    return x\n"]},{"cell_type":"markdown","metadata":{"id":"eQBlOVQU_hUt"},"source":["Test the layer, the output is the same shape as the input:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r-Y8Yqi1_hUt"},"outputs":[],"source":["sample_ffn = FeedForward(512, 2048)\n","\n","print(en_emb.shape)\n","print(sample_ffn(en_emb).shape)"]},{"cell_type":"markdown","metadata":{"id":"8kRUT__Ly9HH"},"source":["Here is the definition of the `EncoderLayer`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ncyS-Ms3i2x_"},"outputs":[],"source":["class EncoderLayer(tf.keras.layers.Layer):\n","  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n","    super().__init__()\n","\n","    self.self_attention = GlobalSelfAttention(\n","        num_heads=num_heads,\n","        key_dim=d_model,\n","        dropout=dropout_rate)\n","\n","    self.ffn = FeedForward(d_model, dff)\n","\n","  def call(self, x):\n","    x = self.self_attention(x)\n","    x = self.ffn(x)\n","    return x"]},{"cell_type":"markdown","metadata":{"id":"QeXHMUlb6q6F"},"source":["And a quick test, the output will have the same shape as the input:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AzZRXdO0mI48"},"outputs":[],"source":["sample_encoder_layer = EncoderLayer(d_model=512, num_heads=8, dff=2048)\n","\n","print(pt_emb.shape)\n","print(sample_encoder_layer(pt_emb).shape)"]},{"cell_type":"markdown","metadata":{"id":"DA6sVo5rlzd3"},"source":["The encoder consists of:\n","\n","- A `PositionalEmbedding` layer at the input.\n","- A stack of `EncoderLayer` layers."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jpEox7gJ8FCI"},"outputs":[],"source":["class Encoder(tf.keras.layers.Layer):\n","  def __init__(self, *, num_layers, d_model, num_heads,\n","               dff, vocab_size, dropout_rate=0.1):\n","    super().__init__()\n","\n","    self.d_model = d_model\n","    self.num_layers = num_layers\n","\n","    self.pos_embedding = PositionalEmbedding(\n","        vocab_size=vocab_size, d_model=d_model)\n","\n","    self.enc_layers = [\n","        EncoderLayer(d_model=d_model,\n","                     num_heads=num_heads,\n","                     dff=dff,\n","                     dropout_rate=dropout_rate)\n","        for _ in range(num_layers)]\n","    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n","\n","  def call(self, x):\n","    # `x` is token-IDs shape: (batch, seq_len)\n","    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n","    \n","    # Add dropout.\n","    x = self.dropout(x)\n","\n","    for i in range(self.num_layers):\n","      x = self.enc_layers[i](x)\n","\n","    return x  # Shape `(batch_size, seq_len, d_model)`."]},{"cell_type":"markdown","metadata":{"id":"texobMBHLBEU"},"source":["Test the encoder:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SDPXTvYgJH8s"},"outputs":[],"source":["# Instantiate the encoder.\n","sample_encoder = Encoder(num_layers=4,\n","                         d_model=512,\n","                         num_heads=8,\n","                         dff=2048,\n","                         vocab_size=8500)\n","\n","sample_encoder_output = sample_encoder(pt, training=False)\n","\n","# Print the shape.\n","print(pt.shape)\n","print(sample_encoder_output.shape)  # Shape `(batch_size, input_seq_len, d_model)`."]},{"cell_type":"markdown","metadata":{"id":"6LO_48Owmx_o"},"source":["### The decoder layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9SoX0-vd1hue"},"outputs":[],"source":["class DecoderLayer(tf.keras.layers.Layer):\n","  def __init__(self,\n","               *,\n","               d_model,\n","               num_heads,\n","               dff,\n","               dropout_rate=0.1):\n","    super(DecoderLayer, self).__init__()\n","\n","    self.causal_self_attention = CausalSelfAttention(\n","        num_heads=num_heads,\n","        key_dim=d_model,\n","        dropout=dropout_rate)\n","    \n","    self.cross_attention = CrossAttention(\n","        num_heads=num_heads,\n","        key_dim=d_model,\n","        dropout=dropout_rate)\n","\n","    self.ffn = FeedForward(d_model, dff)\n","\n","  def call(self, x, context):\n","    x = self.causal_self_attention(x=x)\n","    x = self.cross_attention(x=x, context=context)\n","\n","    # Cache the last attention scores for plotting later\n","    self.last_attn_scores = self.cross_attention.last_attn_scores\n","\n","    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n","    return x"]},{"cell_type":"markdown","metadata":{"id":"a6T3RSR_6nJX"},"source":["Test the decoder layer:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ne2Bqx8k71l0"},"outputs":[],"source":["sample_decoder_layer = DecoderLayer(d_model=512, num_heads=8, dff=2048)\n","\n","sample_decoder_layer_output = sample_decoder_layer(\n","    x=en_emb, context=pt_emb)\n","\n","print(en_emb.shape)\n","print(pt_emb.shape)\n","print(sample_decoder_layer_output.shape)  # `(batch_size, seq_len, d_model)`"]},{"cell_type":"markdown","metadata":{"id":"2q49vtv5lzd3"},"source":["\n","Define the decoder by extending `tf.keras.layers.Layer`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5_d5-PLQXwY"},"outputs":[],"source":["class Decoder(tf.keras.layers.Layer):\n","  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n","               dropout_rate=0.1):\n","    super(Decoder, self).__init__()\n","\n","    self.d_model = d_model\n","    self.num_layers = num_layers\n","\n","    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n","                                             d_model=d_model)\n","    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n","    self.dec_layers = [\n","        DecoderLayer(d_model=d_model, num_heads=num_heads,\n","                     dff=dff, dropout_rate=dropout_rate)\n","        for _ in range(num_layers)]\n","\n","    self.last_attn_scores = None\n","\n","  def call(self, x, context):\n","    # `x` is token-IDs shape (batch, target_seq_len)\n","    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n","\n","    x = self.dropout(x)\n","\n","    for i in range(self.num_layers):\n","      x  = self.dec_layers[i](x, context)\n","\n","    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n","\n","    # The shape of x is (batch_size, target_seq_len, d_model).\n","    return x"]},{"cell_type":"markdown","metadata":{"id":"eALcB--YMmLf"},"source":["Test the decoder:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xyHdG_jWPgKu"},"outputs":[],"source":["# Instantiate the decoder.\n","sample_decoder = Decoder(num_layers=4,\n","                         d_model=512,\n","                         num_heads=8,\n","                         dff=2048,\n","                         vocab_size=8000)\n","\n","output = sample_decoder(\n","    x=en,\n","    context=pt_emb)\n","\n","# Print the shapes.\n","print(en.shape)\n","print(pt_emb.shape)\n","print(output.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ioJ4XJAUAReI"},"outputs":[],"source":["sample_decoder.last_attn_scores.shape  # (batch, heads, target_seq, input_seq)"]},{"cell_type":"markdown","metadata":{"id":"D3uvMP5vNuOV"},"source":["Having created the Transformer encoder and decoder, it's time to build the Transformer model and train it."]},{"cell_type":"markdown","metadata":{"id":"y54xnJnuYgJ7"},"source":["## The Transformer"]},{"cell_type":"markdown","metadata":{"id":"I5vSbJ_gKx7C"},"source":["Create the `Transformer` by extending `tf.keras.Model`:\n","\n","> Note: The [original paper](https://arxiv.org/pdf/1706.03762.pdf), section 3.4, shares the weight matrix between the embedding layer and the final linear layer. To keep things simple, this tutorial uses two separate weight matrices."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PED3bIpOYkBu"},"outputs":[],"source":["class Transformer(tf.keras.Model):\n","  def __init__(self, *, num_layers, d_model, num_heads, dff,\n","               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n","    super().__init__()\n","    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n","                           num_heads=num_heads, dff=dff,\n","                           vocab_size=input_vocab_size,\n","                           dropout_rate=dropout_rate)\n","\n","    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n","                           num_heads=num_heads, dff=dff,\n","                           vocab_size=target_vocab_size,\n","                           dropout_rate=dropout_rate)\n","\n","    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n","\n","  def call(self, inputs):\n","    # To use a Keras model with `.fit` you must pass all your inputs in the\n","    # first argument.\n","    context, x  = inputs\n","\n","    context = self.encoder(context)  # (batch_size, context_len, d_model)\n","\n","    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n","\n","    # Final linear layer output.\n","    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n","\n","    try:\n","      # Drop the keras mask, so it doesn't scale the losses/metrics.\n","      # b/250038731\n","      del logits._keras_mask\n","    except AttributeError:\n","      pass\n","\n","    # Return the final output and the attention weights.\n","    return logits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mzyo6KDfVyhl"},"outputs":[],"source":["num_layers = 4\n","d_model = 128\n","dff = 512\n","num_heads = 8\n","dropout_rate = 0.1"]},{"cell_type":"markdown","metadata":{"id":"g08YOE-zHRqY"},"source":["### Try it out"]},{"cell_type":"markdown","metadata":{"id":"yYbXDEhhlzd6"},"source":["Instantiate the `Transformer` model:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UiysUa--4tOU"},"outputs":[],"source":["transformer = Transformer(\n","    num_layers=num_layers,\n","    d_model=d_model,\n","    num_heads=num_heads,\n","    dff=dff,\n","    input_vocab_size=tokenizers.pt.get_vocab_size().numpy(),\n","    target_vocab_size=tokenizers.en.get_vocab_size().numpy(),\n","    dropout_rate=dropout_rate)"]},{"cell_type":"markdown","metadata":{"id":"Qbw3CYn2tQQx"},"source":["Test it:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c8eO85hpFHmE"},"outputs":[],"source":["output = transformer((pt, en))\n","\n","print(en.shape)\n","print(pt.shape)\n","print(output.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"olTLrK8pAcLd"},"outputs":[],"source":["attn_scores = transformer.decoder.dec_layers[-1].last_attn_scores\n","print(attn_scores.shape)  # (batch, heads, target_seq, input_seq)"]},{"cell_type":"markdown","metadata":{"id":"_jTvJsXquaHW"},"source":["Print the summary of the model:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IsUPhlfEtOjn"},"outputs":[],"source":["transformer.summary()"]},{"cell_type":"markdown","metadata":{"id":"EfoBfC2oQtEy"},"source":["## Training\n","\n","It's time to prepare the model and start training it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iYQdOO1axwEI"},"outputs":[],"source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","  def __init__(self, d_model, warmup_steps=4000):\n","    super().__init__()\n","\n","    self.d_model = d_model\n","    self.d_model = tf.cast(self.d_model, tf.float32)\n","\n","    self.warmup_steps = warmup_steps\n","\n","  def __call__(self, step):\n","    step = tf.cast(step, dtype=tf.float32)\n","    arg1 = tf.math.rsqrt(step)\n","    arg2 = step * (self.warmup_steps ** -1.5)\n","\n","    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"]},{"cell_type":"markdown","metadata":{"id":"fzXq5LWgRN63"},"source":["Instantiate the optimizer (in this example it's `tf.keras.optimizers.Adam`):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7r4scdulztRx"},"outputs":[],"source":["learning_rate = CustomSchedule(d_model)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n","                                     epsilon=1e-9)"]},{"cell_type":"markdown","metadata":{"id":"fTb2S4RnQ8DU"},"source":["Test the custom learning rate scheduler:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xij3MwYVRAAS"},"outputs":[],"source":["plt.plot(learning_rate(tf.range(40000, dtype=tf.float32)))\n","plt.ylabel('Learning Rate')\n","plt.xlabel('Train Step')"]},{"cell_type":"markdown","metadata":{"id":"YgkDE7hzo8r5"},"source":["### Set up the loss and metrics"]},{"cell_type":"markdown","metadata":{"id":"B6y7rNP5lzd6"},"source":["Since the target sequences are padded, it is important to apply a padding mask when calculating the loss. Use the cross-entropy loss function (`tf.keras.losses.SparseCategoricalCrossentropy`):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"67oqVHiT0Eiu"},"outputs":[],"source":["def masked_loss(label, pred):\n","  mask = label != 0\n","  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')\n","  loss = loss_object(label, pred)\n","\n","  mask = tf.cast(mask, dtype=loss.dtype)\n","  loss *= mask\n","\n","  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n","  return loss\n","\n","\n","def masked_accuracy(label, pred):\n","  pred = tf.argmax(pred, axis=2)\n","  label = tf.cast(label, pred.dtype)\n","  match = label == pred\n","\n","  mask = label != 0\n","\n","  match = match & mask\n","\n","  match = tf.cast(match, dtype=tf.float32)\n","  mask = tf.cast(mask, dtype=tf.float32)\n","  return tf.reduce_sum(match)/tf.reduce_sum(mask)"]},{"cell_type":"markdown","metadata":{"id":"xYEasEOsdn5W"},"source":["### Train the model"]},{"cell_type":"markdown","metadata":{"id":"Mk8vwuN24hafK"},"source":["With all the components ready, configure the training procedure using `model.compile`, and then run it with `model.fit`:\n","\n","Note: This takes about an hour to train in Colab."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Una1v0hDlIsT"},"outputs":[],"source":["transformer.compile(\n","    loss=masked_loss,\n","    optimizer=optimizer,\n","    metrics=[masked_accuracy])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jg35qKvVlctp"},"outputs":[],"source":["transformer.fit(train_batches,\n","                epochs=20,\n","                validation_data=val_batches)"]},{"cell_type":"markdown","metadata":{"id":"cxKpqCbzSW6z"},"source":["## Run inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eY_uXsOhSmbb"},"outputs":[],"source":["class Translator(tf.Module):\n","  def __init__(self, tokenizers, transformer):\n","    self.tokenizers = tokenizers\n","    self.transformer = transformer\n","\n","  def __call__(self, sentence, max_length=MAX_TOKENS):\n","    # The input sentence is Portuguese, hence adding the `[START]` and `[END]` tokens.\n","    assert isinstance(sentence, tf.Tensor)\n","    if len(sentence.shape) == 0:\n","      sentence = sentence[tf.newaxis]\n","\n","    sentence = self.tokenizers.pt.tokenize(sentence).to_tensor()\n","\n","    encoder_input = sentence\n","\n","    # As the output language is English, initialize the output with the\n","    # English `[START]` token.\n","    start_end = self.tokenizers.en.tokenize([''])[0]\n","    start = start_end[0][tf.newaxis]\n","    end = start_end[1][tf.newaxis]\n","\n","    # `tf.TensorArray` is required here (instead of a Python list), so that the\n","    # dynamic-loop can be traced by `tf.function`.\n","    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n","    output_array = output_array.write(0, start)\n","\n","    for i in tf.range(max_length):\n","      output = tf.transpose(output_array.stack())\n","      predictions = self.transformer([encoder_input, output], training=False)\n","\n","      # Select the last token from the `seq_len` dimension.\n","      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n","\n","      predicted_id = tf.argmax(predictions, axis=-1)\n","\n","      # Concatenate the `predicted_id` to the output which is given to the\n","      # decoder as its input.\n","      output_array = output_array.write(i+1, predicted_id[0])\n","\n","      if predicted_id == end:\n","        break\n","\n","    output = tf.transpose(output_array.stack())\n","    # The output shape is `(1, tokens)`.\n","    text = tokenizers.en.detokenize(output)[0]  # Shape: `()`.\n","\n","    tokens = tokenizers.en.lookup(output)[0]\n","\n","    # `tf.function` prevents us from using the attention_weights that were\n","    # calculated on the last iteration of the loop.\n","    # So, recalculate them outside the loop.\n","    self.transformer([encoder_input, output[:,:-1]], training=False)\n","    attention_weights = self.transformer.decoder.last_attn_scores\n","\n","    return text, tokens, attention_weights"]},{"cell_type":"markdown","metadata":{"id":"mJ3o-65iS6CN"},"source":["Note: This function uses an unrolled loop, not a dynamic loop. It generates `MAX_TOKENS` on every call. Refer to the [NMT with attention](nmt_with_attention.ipynb) tutorial for an example implementation with a dynamic loop, which can be much more efficient."]},{"cell_type":"markdown","metadata":{"id":"TeUJafisS435"},"source":["Create an instance of this `Translator` class, and try it out a few times:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-NjbvpHUTEia"},"outputs":[],"source":["translator = Translator(tokenizers, transformer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QfHSRdejTFsC"},"outputs":[],"source":["def print_translation(sentence, tokens, ground_truth):\n","  print(f'{\"Input:\":15s}: {sentence}')\n","  print(f'{\"Prediction\":15s}: {tokens.numpy().decode(\"utf-8\")}')\n","  print(f'{\"Ground truth\":15s}: {ground_truth}')"]},{"cell_type":"markdown","metadata":{"id":"buUeDo58TIoD"},"source":["Example 1:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o9CEm4cuTGtw"},"outputs":[],"source":["sentence = 'este é um problema que temos que resolver.'\n","ground_truth = 'this is a problem we have to solve .'\n","\n","translated_text, translated_tokens, attention_weights = translator(\n","    tf.constant(sentence))\n","print_translation(sentence, translated_text, ground_truth)"]},{"cell_type":"markdown","metadata":{"id":"sfJrFBZ6TJxc"},"source":["Example 2:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"elmz_Ly7THuJ"},"outputs":[],"source":["sentence = 'os meus vizinhos ouviram sobre esta ideia.'\n","ground_truth = 'and my neighboring homes heard about this idea .'\n","\n","translated_text, translated_tokens, attention_weights = translator(\n","    tf.constant(sentence))\n","print_translation(sentence, translated_text, ground_truth)"]},{"cell_type":"markdown","metadata":{"id":"EY7NfEjrTOCr"},"source":["Example 3:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bmmtPo3vTOwj"},"outputs":[],"source":["sentence = 'vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.'\n","ground_truth = \"so i'll just share with you some stories very quickly of some magical things that have happened.\"\n","\n","translated_text, translated_tokens, attention_weights = translator(\n","    tf.constant(sentence))\n","print_translation(sentence, translated_text, ground_truth)"]},{"cell_type":"markdown","metadata":{"id":"aB_03k0kTQLb"},"source":["## Create attention plots"]},{"cell_type":"markdown","metadata":{"id":"miZXl9i-TSs6"},"source":["The `Translator` class you created in the previous section returns a dictionary of attention heatmaps you can use to visualize the internal working of the model.\n","\n","For example:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V3m2wcNLTU8K"},"outputs":[],"source":["sentence = 'este é o primeiro livro que eu fiz.'\n","ground_truth = \"this is the first book i've ever done.\"\n","\n","translated_text, translated_tokens, attention_weights = translator(\n","    tf.constant(sentence))\n","print_translation(sentence, translated_text, ground_truth)"]},{"cell_type":"markdown","metadata":{"id":"-rhE_LW7TZ40"},"source":["Create a function that plots the attention when a token is generated:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gKlxYO0JTXzD"},"outputs":[],"source":["def plot_attention_head(in_tokens, translated_tokens, attention):\n","  # The model didn't generate `<START>` in the output. Skip it.\n","  translated_tokens = translated_tokens[1:]\n","\n","  ax = plt.gca()\n","  ax.matshow(attention)\n","  ax.set_xticks(range(len(in_tokens)))\n","  ax.set_yticks(range(len(translated_tokens)))\n","\n","  labels = [label.decode('utf-8') for label in in_tokens.numpy()]\n","  ax.set_xticklabels(\n","      labels, rotation=90)\n","\n","  labels = [label.decode('utf-8') for label in translated_tokens.numpy()]\n","  ax.set_yticklabels(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yI4YWU2uXDeW"},"outputs":[],"source":["head = 0\n","# Shape: `(batch=1, num_heads, seq_len_q, seq_len_k)`.\n","attention_heads = tf.squeeze(attention_weights, 0)\n","attention = attention_heads[head]\n","attention.shape"]},{"cell_type":"markdown","metadata":{"id":"facNouzOXMSu"},"source":["These are the input (Portuguese) tokens:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SMEpyioWTmSN"},"outputs":[],"source":["in_tokens = tf.convert_to_tensor([sentence])\n","in_tokens = tokenizers.pt.tokenize(in_tokens).to_tensor()\n","in_tokens = tokenizers.pt.lookup(in_tokens)[0]\n","in_tokens"]},{"cell_type":"markdown","metadata":{"id":"JLg9HTKCXPKz"},"source":["And these are the output (English translation) tokens:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GzvIo5uYTnHG"},"outputs":[],"source":["translated_tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lrNh47D1ToBD"},"outputs":[],"source":["plot_attention_head(in_tokens, translated_tokens, attention)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iMZr-rI_TrGh"},"outputs":[],"source":["def plot_attention_weights(sentence, translated_tokens, attention_heads):\n","  in_tokens = tf.convert_to_tensor([sentence])\n","  in_tokens = tokenizers.pt.tokenize(in_tokens).to_tensor()\n","  in_tokens = tokenizers.pt.lookup(in_tokens)[0]\n","\n","  fig = plt.figure(figsize=(16, 8))\n","\n","  for h, head in enumerate(attention_heads):\n","    ax = fig.add_subplot(2, 4, h+1)\n","\n","    plot_attention_head(in_tokens, translated_tokens, head)\n","\n","    ax.set_xlabel(f'Head {h+1}')\n","\n","  plt.tight_layout()\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lBMujUb1Tr4C"},"outputs":[],"source":["plot_attention_weights(sentence,\n","                       translated_tokens,\n","                       attention_weights[0])"]},{"cell_type":"markdown","metadata":{"id":"9N5S5IptTtHI"},"source":["The model can handle unfamiliar words. Neither `'triceratops'` nor `'encyclopédia'` are in the input dataset, and the model attempts to transliterate them even without a shared vocabulary. For example:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w0-5gjfWT0CS"},"outputs":[],"source":["sentence = 'Eu li sobre triceratops na enciclopédia.'\n","ground_truth = 'I read about triceratops in the encyclopedia.'\n","\n","translated_text, translated_tokens, attention_weights = translator(\n","    tf.constant(sentence))\n","print_translation(sentence, translated_text, ground_truth)\n","\n","plot_attention_weights(sentence, translated_tokens, attention_weights[0])"]},{"cell_type":"markdown","metadata":{"id":"9zz4uIDbT1OU"},"source":["## Export the model"]},{"cell_type":"markdown","metadata":{"id":"zunHPJJzT4Cz"},"source":["You have tested the model and the inference is working. Next, you can export it as a `tf.saved_model`. To learn about saving and loading a model in the SavedModel format, use [this guide](https://www.tensorflow.org/guide/saved_model).\n","\n","Create a class called `ExportTranslator` by subclassing the `tf.Module` subclass with a `tf.function` on the `__call__` method:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NZhv5h4AT_n5"},"outputs":[],"source":["class ExportTranslator(tf.Module):\n","  def __init__(self, translator):\n","    self.translator = translator\n","\n","  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])\n","  def __call__(self, sentence):\n","    (result,\n","     tokens,\n","     attention_weights) = self.translator(sentence, max_length=MAX_TOKENS)\n","\n","    return result"]},{"cell_type":"markdown","metadata":{"id":"Wad7lUtPUAnf"},"source":["In the above `tf.function` only the output sentence is returned. Thanks to the [non-strict execution](https://tensorflow.org/guide/intro_to_graphs) in `tf.function` any unnecessary values are never computed."]},{"cell_type":"markdown","metadata":{"id":"-7KJEFWI5v84"},"source":["Wrap `translator` in the newly created `ExportTranslator`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wm1_eRPvUCUm"},"outputs":[],"source":["translator = ExportTranslator(translator)"]},{"cell_type":"markdown","metadata":{"id":"7VPH4T5XUDnc"},"source":["Since the model is decoding the predictions using `tf.argmax` the predictions are deterministic. The original model and one reloaded from its `SavedModel` should give identical predictions:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GITRCiAYUE5w"},"outputs":[],"source":["translator('este é o primeiro livro que eu fiz.').numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_v--e1XmUFw3"},"outputs":[],"source":["tf.saved_model.save(translator, export_dir='translator')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5KJSQEzlUGo-"},"outputs":[],"source":["reloaded = tf.saved_model.load('translator')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lIVpKWBNUHhr"},"outputs":[],"source":["reloaded('este é o primeiro livro que eu fiz.').numpy()"]}],"metadata":{"colab":{"last_runtime":{"build_target":"//learning/deepmind/public/tools/ml_python:ml_notebook","kind":"private"},"private_outputs":true,"provenance":[{"file_id":"https://github.com/tensorflow/text/blob/master/docs/tutorials/transformer.ipynb","timestamp":1683737053056}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}